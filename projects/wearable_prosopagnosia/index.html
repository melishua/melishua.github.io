<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Wearable Visual Memory Prothetic for Prosopagnosia​ | Melissa Pan</title> <meta name="author" content="Melissa Pan"> <meta name="description" content="A computer-centred healthcare system for prosopagnosia patients utilizing machine learning and clinical training. Heads up! This will redirect to my old home page, migration to github page is in progress."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;M&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://melishua.github.io/projects/wearable_prosopagnosia/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Melissa Pan</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Wearable Visual Memory Prothetic for Prosopagnosia​</h1> <p class="post-description">A computer-centred healthcare system for prosopagnosia patients utilizing machine learning and clinical training. Heads up! This will redirect to my old home page, migration to github page is in progress.</p> </header> <article> <p><strong>Leverage the power of technology to develop a human-centred system to help people with prosopagnosia.</strong></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/wearable_project-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/wearable_project-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/wearable_project-1400.webp"></source> <img src="/assets/img/wearable_project.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Wearing ISEE" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <i>"Face Recognition and Rehabilitation: A Wearable Assistive and Training System for Prosopagnosia": <a href="assets/img/IEEE_SMC2020_prosopagnosia">PDF</a> </i> </div> <p><br></p> <p>Our work was presented and published at SMC2020:</p> <div class="row"> <iframe width="358" height="200" src="https://www.youtube.com/embed/bd7rJAimunw?si=HWncFO3PtL3Hd7yT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> </div> <h2 id="what-is-prosopagnosia">What is prosopagnosia?</h2> <p>Prosopagnosia (commonly known as <strong>“face-blindness”</strong>) is an impairment in recognizing or remembering (visual memory) faces due to neurological disorder <a href="https://www.psychologytoday.com/ca/basics/prosopagnosia" rel="external nofollow noopener" target="_blank">[1]</a>. Instead of having an inability to see a face – two eyes, one nose, and a mouth – the patients are unable to recognize or remember faces. Thus, prosopagnosics cannot distinguish familiar people by face. Depending on the level of severity, other symptoms range from unable to identify self image, to differentiating faces from other objects <a href="https://www.ninds.nih.gov/Disorders/All-Disorders/Prosopagnosia-Information-Page" rel="external nofollow noopener" target="_blank">[2]</a>.</p> <p>Social awkwardness, anxiety or depression are common complications for prosopagnosics <a href="https://www.ninds.nih.gov/Disorders/All-Disorders/Prosopagnosia-Information-Page" rel="external nofollow noopener" target="_blank">[2]</a>. Relationship development and maintenance are difficult as patients have trouble recognizing family members and friends [2]. While some individuals tend to avoid interactions with people or large social events, others might have developed various social phobias <a href="https://www.thecut.com/2015/07/what-its-like-to-be-profoundly-face-blind.html" rel="external nofollow noopener" target="_blank">[3]</a>.</p> <h2 id="project-goal">Project Goal</h2> <p>The goal of this project was to develop a computer-centred healthcare system for prosopagnosia patients. This system recognizes faces through a camera in real-time using an open-sourced face recognition library, facilitates face-name management with the option to add facial feature annotations to each face, and provides long-term at-home training to improve their face-processing skills.</p> <h2 id="isee">ISEE</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_system_diagram-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_system_diagram-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_system_diagram-1400.webp"></source> <img src="/assets/img/isee_system_diagram.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE system diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <p>An all-in-one Android application that includes features during and after social interactions in a single device.</p> <p>The system has two major modes according to the identified purposes above: <i><b>real-time face recognition mode</b></i> and <i><b>at-home self-training mode</b></i>. The overview of the system design can be organized into three parts: hardware component, real-time component, and training component (left diagram) using three different colours.</p> </div> </div> <h3 id="wearable-device">Wearable device</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <p>The wearable component of the system: camera + wearable medium</p> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_glasses-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_glasses-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_glasses-1400.webp"></source> <img src="/assets/img/isee_glasses.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE glasses" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="real-time-recognition">Real-Time Recognition</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <p>Daily memory assistant prompting name reminder upon social situtations</p> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_recongition_mode1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_recongition_mode1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_recongition_mode1-1400.webp"></source> <img src="/assets/img/isee_recongition_mode1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE real-time mode" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="self-training-tool">Self-Training Tool</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <p>Mimic clinical visual memory training</p> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_training_mode-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_training_mode-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_training_mode-1400.webp"></source> <img src="/assets/img/isee_training_mode.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE training mode" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="isee-implementation">ISEE Implementation:</h2> <div class="row"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_cameras-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_cameras-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_cameras-1400.webp"></source> <img src="/assets/img/isee_cameras.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE system diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <h3>Wearable devices</h3> <p>Besides the PI-camera integrated glasses, the users have various options to hold the phone for the real-time mode: to plug in <i><b>a wearable set</b></i> as the video input source under the hardware component or use the <i><b>phone’s integrated camera</b></i>. The phone can be held by hand, put in the front pocket, or hang by the phone lanyard.</p> </div> </div> <div class="row"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_recongition_mode2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_recongition_mode2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_recongition_mode2-1400.webp"></source> <img src="/assets/img/isee_recongition_mode2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE system diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_recongition_mode3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_recongition_mode3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_recongition_mode3-1400.webp"></source> <img src="/assets/img/isee_recongition_mode3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE system diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <h3>Real-Time Recognition Mode</h3> <li>Video streamed from the perspective of the user to the interacting human subject.</li> <li>Audio notification is given on contact information if match found, else prompt as unknown.</li> <li>The user is able to add a new person as the contact through selecting training images.</li> <li>Supports multi-face recognition.</li> <br> <p>As we can see from the first screenshot that my face was not recognized by ISEE before getting added to the contact list.</p> <p>Then we go ahead to add me as a new person by selecting the image frame that ISEE saved for unknown faces.</p> <p>After that, ISEE will train and update its model immediately.</p> <p>At the end, we can see that ISEE can recognize my face and report “Melissa” both visually and auditorily.</p> </div> </div> <div class="row"> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_training_mode2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_training_mode2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_training_mode2-1400.webp"></source> <img src="/assets/img/isee_training_mode2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ISEE system diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <h3>At-Home Self-Training Mode</h3> <p>The at-home self-training mode is an interactive interface that allows the user to train on their face-naming ability.</p> <p>It is a standalone mode that users can use before or after the real-time training mode.</p> <li>Mimic clinical training to train on face-naming ability</li> <li>Face images fetch from the user’s contact</li> <li>One training cycle contains 15 rounds of sections</li> <li>At the end of each round, the training accuracy and total reaction time will be saved into the database for future analysis</li> <li>Users can view and edit their contact list information as shown in the last figure</li> </div> </div> <h2 id="experiments">Experiments</h2> <h3 id="real-time-recognition-mode">Real-Time Recognition Mode</h3> <p>The team set up the system to test the average reaction of real-time face recognition. We calculated the average reaction time of eight tests. On average, it takes 0.4081 second to compute and output the result.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_experiment1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_experiment1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_experiment1-1400.webp"></source> <img src="/assets/img/isee_experiment1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="at-home-self-training-mode">At-Home Self-Training Mode</h3> <p>A total of 10 participants were divided into one experimental group and one control group, where each group had five participants. Each participant performed five blocks of ten trails of the training using ISEE.</p> <p>For the experimental group, participants were required to perform face-feature naming upon incorrect selection of a face image. The participant has five seconds to list three facial features with the correct image.</p> <p>For the control group, participants did not perform feature naming where they learn the correct face for five seconds on their own. The hypothesis is that face-feature naming allows the participant to acquire a better holistic understanding of the training face image.</p> <p>I and my team recorded reaction time and accuracy for each block of the face recognition task. The figures below show participants’ accuracy and reaction time in each block of trials. It can be seen that there is a general improvement in accuracy and reaction time for both the experimental and control group where the experimental group has a slightly better performance.</p> <p>Accuracy and Reaction Time Trend:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/isee_experiment2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/isee_experiment2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/isee_experiment2-1400.webp"></source> <img src="/assets/img/isee_experiment2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="future-directions">Future Directions</h2> <ul> <li>Real Prosopagnosia Patient</li> <li>EEG Signal Feedback</li> <li>Face Flashback Training</li> <li>Wearable Wifi/bluetooth Integration</li> <li>Camera Upgrade</li> <li>Computation Speed Optimization</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wearable_project-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wearable_project-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wearable_project-1400.webp"></source> <img src="/assets/img/publication_preview/wearable_project.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wearable_project.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9283058" class="col-sm-8"> <div class="title">Face Recognition and Rehabilitation: A Wearable Assistive and Training System for Prosopagnosia</div> <div class="author"> Steve Mann, Zhiyang Pan, Yi Tao, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Anqi Gao, Xingchen Tao, Danson Evan Garcia, Dawei Shi, Georges Kannan' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In 2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/SMC42975.2020.9283058"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/SMC42975.2020.9283058" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Melissa Pan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>